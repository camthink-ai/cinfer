import base64
import io
import os
import time
from typing import Any, Dict, List, Optional

import cv2
import numpy as np
import logging

from .base import AsyncEngine, EngineInfo, InferenceInput, InferenceOutput, InferenceResult, ResourceRequirements
from PIL import Image
import requests
import numpy as np

logger = logging.getLogger(__name__)

try:
    from paddleocr import PaddleOCR
except ImportError:
    logger.warning("WARNING: PaddleOCR library not found. OCREngine will not be available.")

try:
    import paddle
except ImportError:
    logger.warning(
        "WARNING: paddle library not found. OCREngine will not be available.")


class OCREngine(AsyncEngine):
    ENGINE_NAME = "OCREngine"

    def __init__(self, max_workers: Optional[int] = None, queue_size: Optional[int] = None):
        if PaddleOCR is None:
            raise RuntimeError(
                "PaddleOCR library is not installed. "
                "Please install it to use OCREngine (e.g., 'pip install paddleocr==3.0.0')."
            )

        if paddle is None:
            raise RuntimeError(
                "PaddlePaddle library is not installed. "
                "Please install it to enable OCREngine (e.g., 'python -m pip install paddlepaddle-gpu==3.0.0 -i https://www.paddlepaddle.org.cn/packages/stable/cu126/')."
            )

        super().__init__(max_workers=max_workers, queue_size=queue_size)

        self._session = None
        self._model_loaded = False
        self.device = ""

    def _initialize_paddle_runtime(self) -> bool:
        """åˆå§‹åŒ–å¼•æ“"""
        try:
            # è®¾ç½® Paddle è®¾å¤‡
            if paddle.is_compiled_with_cuda():
                paddle.set_device('gpu')
                logger.info("ä½¿ç”¨ GPU è¿›è¡Œ OCR æ¨ç†")
                print("ä½¿ç”¨ GPU è¿›è¡Œ OCR æ¨ç†")
                self.device = 'gpu'
            else:
                paddle.set_device('cpu')
                logger.info("ä½¿ç”¨ CPU è¿›è¡Œ OCR æ¨ç†")
                print("ä½¿ç”¨ CPU è¿›è¡Œ OCR æ¨ç†")
                self.device = 'cpu'
            return True

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            self._model_loaded = False
            return False

    def initialize(self, engine_config: Dict[str, Any]) -> bool:
        super_init_ok = super().initialize(engine_config)
        if not super_init_ok:
            return False
        return self._initialize_paddle_runtime()

    def _load_model_specifico(self, model_path: str, model_config: Dict[str, Any]) -> bool:
        """åŠ è½½OCRæ¨¡å‹å¹¶æ ¹æ®å…³é”®å­—è¯†åˆ«æ£€æµ‹å’Œè¯†åˆ«æ¨¡å‹è·¯å¾„"""
        import os

        try:
            logger.info(f"æ­£åœ¨æ‰«ææ¨¡å‹è·¯å¾„: {model_path}")

            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not os.path.exists(model_path):
                raise ValueError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")

            # è·å–è·¯å¾„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¤¹
            folders = []
            for item in os.listdir(model_path):
                item_path = os.path.join(model_path, item)
                if os.path.isdir(item_path):
                    folders.append((item, item_path))

            if not folders:
                raise ValueError(f"è·¯å¾„ {model_path} ä¸‹æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶å¤¹")

            logger.info(f"å‘ç° {len(folders)} ä¸ªæ–‡ä»¶å¤¹: {[name for name, _ in folders]}")

            # æ ¹æ®å…³é”®å­—è¯†åˆ«æ¨¡å‹è·¯å¾„ï¼Œä¼˜å…ˆè¯†åˆ«æœåŠ¡çº§æ¨¡å‹
            det_model_path = None
            rec_model_path = None
            cls_model_path = None

            for folder_name, folder_path in folders:
                folder_lower = folder_name.lower()

                # æ£€æµ‹æ¨¡å‹è·¯å¾„è¯†åˆ«
                if 'det' in folder_lower:
                    det_model_path = folder_path
                    logger.info(f"è¯†åˆ«åˆ°æ£€æµ‹æ¨¡å‹: {folder_name} -> {folder_path}")
                # è¯†åˆ«æ¨¡å‹è·¯å¾„è¯†åˆ«
                elif 'rec' in folder_lower:
                    rec_model_path = folder_path
                    logger.info(f"è¯†åˆ«åˆ°è¯†åˆ«æ¨¡å‹: {folder_name} -> {folder_path}")
                # åˆ†ç±»æ¨¡å‹è·¯å¾„è¯†åˆ«ï¼ˆå¯é€‰ï¼‰
                elif 'cls' in folder_lower or 'angle' in folder_lower:
                    cls_model_path = folder_path
                    logger.info(f"è¯†åˆ«åˆ°åˆ†ç±»æ¨¡å‹: {folder_name} -> {folder_path}")

            # éªŒè¯æ˜¯å¦æ‰¾åˆ°äº†å¿…è¦çš„æ¨¡å‹
            if det_model_path is None:
                logger.warning("æœªæ‰¾åˆ°åŒ…å«'det'å…³é”®å­—çš„æ£€æµ‹æ¨¡å‹æ–‡ä»¶å¤¹")
            if rec_model_path is None:
                logger.warning("æœªæ‰¾åˆ°åŒ…å«'rec'å…³é”®å­—çš„è¯†åˆ«æ¨¡å‹æ–‡ä»¶å¤¹")

            self._session = PaddleOCR(
                text_detection_model_dir=det_model_path,
                text_recognition_model_dir=rec_model_path,
                text_detection_model_name="PP-OCRv5_server_det",
                text_recognition_model_name="PP-OCRv5_server_rec",
                use_doc_orientation_classify=False,
                use_doc_unwarping=False,
                use_textline_orientation=False,
            )

            logger.info(f"PaddleOCRæ¨¡å‹åŠ è½½æˆåŠŸ")
            self._model_loaded = True
            return True

        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}", exc_info=True)
            self._model_loaded = False
            return False

    def _preprocess_input(self, raw_inputs: List[InferenceInput]) -> Dict[str, List[np.ndarray]]:
        """
        OCR é¢„å¤„ç†ï¼šä» InferenceInput ä¸­æå–å›¾åƒæ•°æ®å¹¶è½¬æ¢ä¸ºå›¾åƒæ•°ç»„
        åªæ”¯æŒä»¥ä¸‹è¾“å…¥æ ¼å¼ï¼š
        - dict åŒ…å« 'url' é”®
        - dict åŒ…å« 'image_base64' æˆ– 'b64' é”®
        - ç›´æ¥çš„ Base64 å­—ç¬¦ä¸²
        - ç›´æ¥çš„ URL å­—ç¬¦ä¸²
        """
        images: List[np.ndarray] = []

        for idx, inp in enumerate(raw_inputs):
            data = inp.data
            img = None

            try:
                logger.info(f"ğŸ” [ç´¢å¼• {idx}] å¤„ç†è¾“å…¥æ•°æ®ç±»å‹: {type(data)}")
                logger.info(f"ğŸ” [ç´¢å¼• {idx}] æ•°æ®å†…å®¹é¢„è§ˆ: {str(data)[:100]}...")

                # å¤„ç† URL (å­—å…¸æ ¼å¼)
                if isinstance(data, dict) and "url" in data:
                    url = data["url"]
                    logger.info(f"ğŸ“¥ [ç´¢å¼• {idx}] æ£€æµ‹åˆ°å­—å…¸æ ¼å¼çš„URL: {url}")
                    img = self._download_image_as_array(url, idx)

                # å¤„ç† URL (ç›´æ¥å­—ç¬¦ä¸²)
                elif isinstance(data, str) and data.lower().startswith("http"):
                    logger.info(f"ğŸ“¥ [ç´¢å¼• {idx}] æ£€æµ‹åˆ°å­—ç¬¦ä¸²æ ¼å¼çš„URL: {data}")
                    img = self._download_image_as_array(data, idx)

                # å¤„ç† Base64 (å­—å…¸æ ¼å¼)
                elif isinstance(data, dict) and ("image_base64" in data or "b64" in data):
                    key = "image_base64" if "image_base64" in data else "b64"
                    logger.info(f"ğŸ“¥ [ç´¢å¼• {idx}] æ£€æµ‹åˆ°å­—å…¸æ ¼å¼çš„Base64ï¼Œé”®å: {key}")
                    img = self._decode_base64_to_image(data[key], idx)

                # å¤„ç† Base64 (ç›´æ¥å­—ç¬¦ä¸²)
                elif isinstance(data, str):
                    logger.info(f"ğŸ“¥ [ç´¢å¼• {idx}] æ£€æµ‹åˆ°å­—ç¬¦ä¸²æ ¼å¼ï¼Œåˆ¤æ–­ä¸ºBase64")
                    b64_str = data.split(",", 1)[1] if data.startswith("data:") and "," in data else data
                    img = self._decode_base64_to_image(b64_str, idx)

                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥æ•°æ®æ ¼å¼ at index {idx}: {type(data)}. ä»…æ”¯æŒ URL å’Œ Base64 æ ¼å¼")

                # æ ‡å‡†åŒ–å›¾åƒæ ¼å¼
                if img is not None:
                    img_normalized = self._normalize_image_channels(img, idx)
                    images.append(img_normalized)
                    logger.info(f"âœ… [ç´¢å¼• {idx}] æˆåŠŸå¤„ç†ï¼Œå›¾åƒå°ºå¯¸: {img_normalized.shape}")
                else:
                    raise ValueError(f"å¤„ç†è¾“å…¥ {idx} å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆå›¾åƒ")

            except Exception as e:
                msg = f"é¢„å¤„ç†å¤±è´¥ at index {idx}, input={type(data)}, error={e}"
                logger.error(msg, exc_info=True)
                raise ValueError(msg)

        if not images:
            raise ValueError("æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å›¾åƒæ•°ç»„")

        logger.info(f"ğŸ‰ é¢„å¤„ç†å®Œæˆ: {len(images)} ä¸ªå›¾åƒæ•°ç»„")
        return {"images": images}

    def _postprocess_output(self, raw_outputs: List[Any]) -> List[InferenceOutput]:
        """
        OCRåå¤„ç†ï¼šå°†PaddleOCRçš„åŸå§‹è¾“å‡ºè½¬æ¢ä¸ºæ ‡å‡†çš„InferenceOutputæ ¼å¼

        Args:
            raw_outputs: PaddleOCRè¿”å›çš„åŸå§‹ç»“æœåˆ—è¡¨ï¼Œå¯èƒ½åŒ…å«å¤šç§æ ¼å¼çš„æ•°æ®

        Returns:
            List[InferenceOutput]: æ ‡å‡†åŒ–çš„æ¨ç†è¾“å‡ºåˆ—è¡¨
        """
        # ä¸ºæ‰¹å¤„ç†æ„å»ºç»“æœç»“æ„
        batch_results = []

        # å¤„ç†å•ä¸ªå›¾åƒçš„ç»“æœï¼ˆå¦‚æœæ˜¯æ‰¹å¤„ç†ï¼Œè¿™é‡Œéœ€è¦å¾ªç¯å¤„ç†å¤šä¸ªå›¾åƒï¼‰
        image_result = {
            "image_id": 0,  # å›¾åƒç´¢å¼•æˆ–ID
            "detections": []  # è¯¥å›¾åƒçš„æ‰€æœ‰æ£€æµ‹ç»“æœ
        }

        # æå–è¯†åˆ«çš„æ–‡æœ¬å†…å®¹
        if raw_outputs and len(raw_outputs) > 0:
            result_data = raw_outputs[0]
            texts = result_data.get('rec_texts', [])
            scores = result_data.get('rec_scores', [])
            polys = result_data.get('rec_polys', []) or result_data.get('rec_boxes', [])

            for i, text in enumerate(texts):
                confidence = scores[i] if i < len(scores) else 0.0

                # å¤„ç†åæ ‡è½¬æ¢ä¸º [x, y, w, h] æ ¼å¼
                if i < len(polys) and polys[i] is not None:
                    coords = polys[i].tolist() if hasattr(polys[i], 'tolist') else polys[i]

                    # ä»å¤šè¾¹å½¢åæ ‡è®¡ç®—è¾¹ç•Œæ¡†
                    if coords and len(coords) > 0:
                        x_coords = [point[0] for point in coords]
                        y_coords = [point[1] for point in coords]

                        # è®¡ç®—è¾¹ç•Œæ¡†åæ ‡
                        left = min(x_coords)
                        top = min(y_coords)
                        right = max(x_coords)
                        bottom = max(y_coords)

                        # è½¬æ¢ä¸º [x, y, w, h] æ ¼å¼ï¼ˆåˆ†è¾¨ç‡åæ ‡ï¼Œintç±»å‹ï¼‰
                        x = int(left)
                        y = int(top)
                        w = int(right - left)
                        h = int(bottom - top)

                        coords = [x, y, w, h]
                    else:
                        coords = [0, 0, 0, 0]
                else:
                    coords = [0, 0, 0, 0]

                # æ„å»ºæ£€æµ‹ç»“æœ
                detection: Dict[str, Any] = {
                    "coords": coords,
                    "confidence": round(float(confidence), 2),
                    "text": text
                }

                image_result["detections"].append(detection)

        batch_results.append(image_result)

        return [InferenceOutput(data=batch_results)]

    def _batch_process(self, inputs_batch: List[Dict[str, np.ndarray]]) -> List[List[np.ndarray]]:
        """
        æ‰¹å¤„ç†OCRæ¨ç†

        Args:
            inputs_batch: æ‰¹é‡è¾“å…¥æ•°æ®ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«å›¾åƒæ•°æ®

        Returns:
            List[Any]: æ‰¹é‡OCRæ¨ç†ç»“æœ
        """
        if not self._session:
            raise RuntimeError("Paddle OCR session not initialized.")

        results_batch = []
        for single_input_dict in inputs_batch:
            # è·å–å›¾åƒæ•°æ®
            images = single_input_dict.get("images")
            if images is None:
                raise ValueError("No 'images' key found in input data.")

            # æ‰§è¡ŒOCRæ¨ç†
            ocr_result = self._session.predict(images)
            results_batch.append(ocr_result)

        return results_batch

    def predict(self, inputs: List[InferenceInput]) -> InferenceResult:
        if not self._model_loaded or not self._session:
            return InferenceResult(success=False, error_message="Paddle model not loaded.")

        start_time_sec = time.time()  # Corrected

        try:
            # é¢„å¤„ç†
            if self._processor:
                logger.info(f"Processor: {self._processor}")
                preprocessed_data_dict = self._processor.preprocess(inputs)
            else:
                logger.info(f"No processor found. Using default preprocess_input.")
                preprocessed_data_dict = self._preprocess_input(inputs)

            logger.info(f"Preprocessed data keys: {list(preprocessed_data_dict.keys())}")

            # æ‰¹å¤„ç†æ¨ç†
            raw_outputs_list = self._batch_process([preprocessed_data_dict])
            raw_outputs_for_this_call = raw_outputs_list[0]

            # åå¤„ç†
            if self._processor:
                final_outputs = self._processor.postprocess(raw_outputs_for_this_call)
            else:
                final_outputs = self._postprocess_output(raw_outputs_for_this_call)

            logger.info(f"Final outputs count: {len(final_outputs)}")
            processing_time_ms = (time.time() - start_time_sec) * 1000

            return InferenceResult(success=True, outputs=final_outputs,processing_time_ms=processing_time_ms)
        except Exception as e:
            logger.error(f"Error during Paddl prediction: {e}")
            return InferenceResult(success=False, error_message=str(e),
                                   processing_time_ms=(time.time() - start_time_sec) * 1000)  # Corrected

    def get_info(self) -> EngineInfo:
        """è¿”å›OCRå¼•æ“ä¿¡æ¯"""
        engine_info = EngineInfo(
            engine_name=self.ENGINE_NAME,
            engine_version=paddle.__version__ if paddle else "N/A",
            model_loaded=self._model_loaded,
            loaded_model_path=None,
            available_devices=[],
            current_device=None,
            engine_status="",
            additional_info={
                "session_providers": [],
                "engine_config_providers": "",

                "input_names": {
                  "name": "input_name",
                  "type": "tensor",
                  "shape": [1, 3, 224, 224]
                },
                "output_names": {
                  "name": "output_name",
                  "type": "tensor",
                  "shape": [1, 1000]
                },
                "input_shapes": [],
                "models_type": [],
                "models_labels": [],
                "algorithm": [],

                "desc": []
            }
        )
        logger.info(f"EngineInfo: {engine_info}")
        return engine_info

    def get_resource_requirements(self) -> ResourceRequirements:
        mem_usage = 0.0
        return ResourceRequirements(
            cpu_cores=1,
            memory_gb=0.5,
            gpu_count=1,
        )

    def release(self) -> bool:
        """é‡Šæ”¾èµ„æº"""
        try:
            logger.info("é‡Šæ”¾ OCR å¼•æ“èµ„æº")

            if self._session:
                self._session = None
                logger.info("OCR ä¼šè¯å·²æ¸…ç†")

            # æ¸…ç† PaddlePaddle çš„ GPU æ˜¾å­˜ç¼“å­˜
            if paddle.is_compiled_with_cuda():
                paddle.device.cuda.empty_cache()
                logger.info("GPU ç¼“å­˜å·²æ¸…ç†")

            self._model_loaded = False
            return True

        except Exception as e:
            logger.error(f"é‡Šæ”¾èµ„æºå¤±è´¥: {e}")
            return False

    def test_inference(self, test_inputs: Optional[List[InferenceInput]] = None) -> InferenceResult:
        """
        æµ‹è¯•æ¨ç†å¼•æ“ç«¯åˆ°ç«¯å¯ç”¨æ€§
        """
        logger.info(f"Performing test inference on {self.__class__.__name__}...")
        start_time_sec = time.time()

        try:
            # åˆ›å»ºè™šæ‹Ÿå›¾åƒæ•°æ®ç”¨äºæµ‹è¯•
            # OCRé€šå¸¸å¤„ç†BGRæ ¼å¼çš„å›¾åƒ (height, width, channels)
            height, width, channels = 640, 640, 3
            logger.debug(f"OCRæµ‹è¯•è¾“å…¥ç»´åº¦: [{height}, {width}, {channels}]")

            # ç”Ÿæˆéšæœºå›¾åƒæ•°æ® (0-255èŒƒå›´ï¼Œuint8ç±»å‹ï¼ŒBGRæ ¼å¼)
            raw_img = np.random.randint(0, 255, (height, width, channels), dtype=np.uint8)

            # æ‰§è¡Œæ‰¹å¤„ç†æ¨ç†æµ‹è¯•
            _ = self._batch_process([{"images": raw_img}])

            end_time_sec = (time.time() - start_time_sec) * 1000

            logger.info(f"OCR test inference completed successfully in {end_time_sec:.2f}ms")

            return InferenceResult(success=True, processing_time_ms=end_time_sec)

        except Exception as e:
            end_time_sec = (time.time() - start_time_sec) * 1000
            logger.error(f"Exception during test inference: {e}")
            return InferenceResult(
                success=False, error_message=str(e), processing_time_ms=end_time_sec)


    def _download_image_as_array(self, url: str, idx: int) -> np.ndarray:
        """ä» URL ä¸‹è½½å›¾åƒå¹¶ç›´æ¥è¿”å›å›¾åƒæ•°ç»„"""
        try:
            logger.info(f"ğŸ“¡ [ç´¢å¼• {idx}] æ­£åœ¨ä¸‹è½½å›¾åƒ: {url}")
            resp = requests.get(url, timeout=10)
            resp.raise_for_status()

            # æ£€æŸ¥å†…å®¹ç±»å‹
            ct = resp.headers.get("Content-Type", "")
            if not ct.startswith("image/"):
                raise ValueError(f"URL æœªè¿”å›å›¾åƒå†…å®¹: Content-Type={ct}")

            # è§£ç å›¾åƒ
            arr = np.frombuffer(resp.content, dtype=np.uint8)
            img = cv2.imdecode(arr, cv2.IMREAD_COLOR)

            if img is None:
                raise ValueError("æ— æ³•è§£ç ä¸‹è½½çš„å›¾åƒ")

            logger.info(f"âœ… [ç´¢å¼• {idx}] æˆåŠŸä¸‹è½½å›¾åƒ: shape={img.shape}")
            return img

        except Exception as e:
            logger.error(f"âŒ [ç´¢å¼• {idx}] ä» URL ä¸‹è½½å›¾åƒå¤±è´¥, url={url}: {e}")
            raise ValueError(f"ä» URL ä¸‹è½½å›¾åƒå¤±è´¥ [ç´¢å¼• {idx}], url={url}: {e}")

    def _decode_base64_to_image(self, b64_str: str, idx: int) -> np.ndarray:
        """å°† Base64 å­—ç¬¦ä¸²è§£ç ä¸ºå›¾åƒæ•°ç»„"""
        try:
            logger.info(f"ğŸ”“ [ç´¢å¼• {idx}] æ­£åœ¨è§£ç  Base64 å›¾åƒ...")

            # è§£ç  Base64
            b64_str = b64_str.strip()
            img_bytes = base64.b64decode(b64_str)

            # å°è¯•ç”¨ OpenCV è§£ç 
            arr = np.frombuffer(img_bytes, dtype=np.uint8)
            img = cv2.imdecode(arr, cv2.IMREAD_COLOR)

            if img is None:
                # å›é€€åˆ° PIL
                logger.info(f"ğŸ”„ [ç´¢å¼• {idx}] OpenCV è§£ç å¤±è´¥ï¼Œå°è¯• PIL...")
                pil_img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
                img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

            logger.info(f"âœ… [ç´¢å¼• {idx}] æˆåŠŸè§£ç  Base64 å›¾åƒ: shape={img.shape}")
            return img

        except Exception as e:
            logger.error(f"âŒ [ç´¢å¼• {idx}] è§£ç  Base64 å›¾åƒå¤±è´¥: {e}")
            raise ValueError(f"è§£ç  Base64 å›¾åƒå¤±è´¥ [ç´¢å¼• {idx}]: {e}")

    def _normalize_image_channels(self, img: np.ndarray, idx: int) -> np.ndarray:
        """æ ‡å‡†åŒ–å›¾åƒé€šé“æ ¼å¼ä¸º BGR ä¸‰é€šé“"""
        try:
            logger.debug(f"ğŸ”§ [ç´¢å¼• {idx}] æ ‡å‡†åŒ–å›¾åƒé€šé“ï¼ŒåŸå§‹å½¢çŠ¶: {img.shape}")

            if len(img.shape) == 2:
                # ç°åº¦å›¾è½¬ BGR
                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                logger.debug(f"ğŸ”„ [ç´¢å¼• {idx}] ç°åº¦å›¾å·²è½¬æ¢ä¸ºBGR")
            elif len(img.shape) == 3:
                if img.shape[2] == 1:
                    # å•é€šé“è½¬ BGR
                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
                    logger.debug(f"ğŸ”„ [ç´¢å¼• {idx}] å•é€šé“å›¾å·²è½¬æ¢ä¸ºBGR")
                elif img.shape[2] == 3:
                    # å·²ç»æ˜¯ä¸‰é€šé“ï¼Œä¿æŒä¸å˜
                    logger.debug(f"âœ… [ç´¢å¼• {idx}] å·²æ˜¯BGRä¸‰é€šé“")
                elif img.shape[2] == 4:
                    # RGBAè½¬BGRï¼Œä¸¢å¼ƒAlphaé€šé“
                    img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)
                    logger.debug(f"ğŸ”„ [ç´¢å¼• {idx}] RGBAå›¾å·²è½¬æ¢ä¸ºBGR")
                else:
                    # è¶…è¿‡4é€šé“ï¼Œå–å‰3ä¸ªé€šé“
                    img = img[:, :, :3]
                    logger.warning(f"âš ï¸ [ç´¢å¼• {idx}] å¤šé€šé“å›¾åƒ({img.shape[2]}é€šé“)å·²æˆªå–å‰3ä¸ªé€šé“")
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å›¾åƒç»´åº¦: {img.shape}")

            # ç¡®ä¿æœ€ç»ˆæ˜¯ä¸‰é€šé“BGRæ ¼å¼
            if len(img.shape) != 3 or img.shape[2] != 3:
                raise ValueError(f"é€šé“è½¬æ¢åä»éä¸‰é€šé“å›¾åƒï¼Œshape={img.shape}")

            logger.debug(f"âœ… [ç´¢å¼• {idx}] é€šé“æ ‡å‡†åŒ–å®Œæˆ: {img.shape}")
            return img

        except Exception as e:
            logger.error(f"âŒ [ç´¢å¼• {idx}] å›¾åƒé€šé“æ ‡å‡†åŒ–å¤±è´¥: {e}")
            raise ValueError(f"å›¾åƒé€šé“æ ‡å‡†åŒ–å¤±è´¥ [ç´¢å¼• {idx}]: {e}")